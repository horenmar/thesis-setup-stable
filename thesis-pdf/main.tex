\input ctustyle
\input pdfuni
\input glosdata
\input opmac-bib

\parskip=\medskipamount \parindent=0pt

\worktype [B/EN]
\faculty {F3}
\department {Katedra řídící techniky}
\title {The Use of Symbolic Execution for Testing of Real-Time
        Safety-Related Software}
\titleCZ {Využití symbolické exekuce pro testování real-time,
          bezpečnostně kritického softwaru}
\author {Martin Hořeňovský}
\authorinfo {horenmar@fel.cvut.cz}
\supervisor {Ing. Michal Sojka, Ph.D.}
\studyinfo {Otevřená informatika - Informatika a počítačové vědy}
\date {Květen 2015}
\abstractEN {Safety critical software is hard!.}
\keywordsEN {Symbolic execution, KLEE, automatic testing,
             security-critical systems, automotive domain}
\abstractCZ {Safety critical software is hard!
             \rfc{Translate the english abstract}}
\keywordsCZ {Symbolická exekuce, KLEE, automatické testování,
             bezpečnostně kritický software, automobilová doména
             \rfc{Standartní překlad??}}
\thanks{I would like to thank my supervisor Ing. Michal Sojka, Ph.D.
        for having patience with my lazy ass. \rfc{Selfcensorship?}
        I also want to thank Petr Olšák for creating almost unified template
        for CTU.}
\declaration {
I hereby declare that I made this on my own and I declared
all used sources according to ``Metodický pokyn o dodržování
etických principů při přípravě vysokoškolských závěřečných prací''

\vskip 4cm
\chyph
Prohlašuji, že jsem předloženou práci vypracoval samostatně
a že jsem uvedl veškeré použité informační zdroje v souladu
s Metodickým pokynem o dodržování etických principů při přípravě
vysokoškolských závěrečných prací.

\signature
}


%Some draft iteration related "defines"
\draft %-- Remove this to finalize pdf.
\savetoner
 
\makefront
\chap Introduction

Words...


\sec Motivation

\sec What is the goal

\sec Structure

\sec Following text



\chap Background and related software

\sec Safety-critical software and security

Safety-critical systems are those systems whose malfunction and/or failure
might result in death (or grievous injury) of people, severe damage to and/or
loss of equipment and environmental damage. These systems are increasingly
often implemented in software, as opposed to hardware, and new methods of
software defect prevention are needed.

There are various ways to decrease the number and frequency of software
malfunctions, such as specific development methodologies (ie MISRA C%
\urlnote{http://www.misra.org.uk/MISRAHome/WhatisMISRA/tabid/66/Default.aspx},
and JSF-AV C++ coding standards\urlnote{http://www.stroustrup.com/JSF-AV-rules.pdf})
which aim to provide safer subset of the language, thus decreasing possible
space for defects and set requirements for testing rigour. Similarly, since
compilation is another potential source of software defects, there are formally
provable compilers\urlnote{http://compcert.inria.fr/}.

In general, safety-critical systems are expected to be hard real-time and to be
fully defined for all possible inputs. This means that software contained
within must always respond under a fixed time-limit and have to fully define
its failure modes, even if the response is just turning off motor and engaging
emergency breaks.

\sec Symbolic execution

The term symbolic execution has been coined in year 1976 by James C. King in
article Symbolic execution and program testing.%
\cite[symbolic-execution-article] Since then symbolic execution has been
implemented by various tools for various languages, from x86 assembly%
\cite[s2e-paper], LLVM's IR (from C/C++)\cite[klee-paper, c9-paper] to higher
level languages such as the .NET framework.\cite[pex-repair-paper]

The contents of rest of this section are heavily based on the KLEE paper%
\cite[klee-paper] and the S2E paper\cite[s2e-paper].
Symbolic execution is a testing technique where program is run through an
interpreter, which allows for inputs to be symbolic as opposed to concrete.
This allows the interpreter to go through all possible paths in a program,
without having to generate all possible inputs. This also allows to connect
specific branches in the program with constraints upon inputs that lead there.

Consider the following function:
\begtt
int is_odd(int n){
    if (n % 2) {
        return 1;
    } else {
        return 0;
    }
}
\endtt
It has $2^{32}$ possible concrete inputs, but as can be easily seen,
has only two paths through. Symbolic testing allows us to find both paths
without having to explore all $2^{32}$ inputs. If I mark the input as symbolic
and use KLEE to test this function, it outputs both paths and gives concretized
values that give full coverage.
\begtt
KLEE: done: total instructions = 29
KLEE: done: completed paths = 2
KLEE: done: generated tests = 2
...
args       : ['is_odd.o']
num objects: 1
object    0: name: 'n'
object    0: size: 4
object    0: data: 0
...
args       : ['is_odd.o']
num objects: 1
object    0: name: 'n'
object    0: size: 4
object    0: data: 1
\endtt

Unlike with fuzzing, time required for symbolic execution of any given program
doesn't increase exponentially with size of input, but rather increases with
amount of branches (possible paths) through the program. This allows use of
symbolic testing on much larger programs than just using random inputs. 

On the other hand, certain kinds of conditional branching are more or less
unsolvable. Consider checking cryptographic hash of a symbolic value against
predetermined result. For symbolic tool to be able to give us a concrete value
or a set of constraints is asking it to reverse a cryptographic hash, which is
generally regarded impossible without brute-force testing the input space, and
in special cases might be impossible completely. Other problematic constructs
are unbounded loops (IE those waiting for a hardware response) and infinite
loops, which prevent symbolic execution from terminating.

Various solutions to increase path coverage and exist, including parallelizing
independent paths\cite[c9-paper], usage of heuristics to guide search%
\cite[klee-paper, symdrive-paper, c9-paper, kite-paper], usage of annotations%
\cite[symdrive-paper] and selective symbolic execution.\cite[s2e-paper]

\secc Existing tools

There are various existing tools for symbolic execution, many of which are
based on KLEE.\cite[symdrive-paper, c9-paper, s2e-paper, kite-paper]

Cloud9\urlnote{http://cloud9.epfl.ch/}
is a symbolic executor that can scale over clusters of machines, and
a cloud service for testing software.\cite[c9-paper] It's innovation is dynamic
partitioning of search space while having a shared-nothing architecture. It is
also capable of executing C++ code.

S2E\urlnote{http://s2e.epfl.ch/}
is a platform for analysing large scale programs In-Vivo. It accomplishes
this by using{\em selective symbolic execution} a technique that automatically
minimalizes amount of symbolically executed code within a binary. Together with
relaxed execution consistency, this allows S2E to analyse code as run in its
real environment.\cite[s2e-paper]

SymDrive\urlnote{http://research.cs.wisc.edu/sonar/projects/symdrive/}
is tool for testing Linux and FreeBSD drivers without hardware.%
\cite[symdrive-paper] It uses static-analysis to automatically find driver
entry points and loops, which often allows it to test a driver without
requiring any modifications by its author and if it cannot create modified
driver automatically, it alerts the developer as to what changes are required.%
\cite[symdrive-paper]

Kite\urlnote{http://www.cs.ubc.ca/labs/isd/Projects/Kite/}
is a KLEE based that prunes its search space whenever a path is proven
to be infeasible. It is based on recent improvements of CDCL SAT solvers and
uses markedly different exploration strategy from other tools, in that it
looks for paths which allow it to ``learn'' the most, that is, prune the search
space the most.\cite[kite-paper]

\sec KLEE

KLEE is a symbolic execution tool primarily geared towards performing
high-coverage tests on programs originally created by Cadar et al.%
\cite[klee-paper]
It is built on the LLVM compiler infrastructure, using its Clang front-end to
convert C code to LLVM IR representation, which it then works on.

While its original purpose was to test general purpose programs, we\rfc{I?}
decided to test its fitness for testing real-time safety critical software,
because such software's number of paths through code is relatively small.

By itself, KLEE can find and show paths that lead to any of
\begitems
* Assertion violation
* Access outside of allocated memory
* Null pointer dereference
\enditems

During my work on this thesis, KLEE was also extended to handle integer oveflow
checking, but needs support from the compiler.

\secc KLEE integer overflow checking

When I started to work on using KLEE for testing real-time safety-critical
software, it was unable to detect integer overflow. In a case of parallel
development, both Dariz Luca and I independently added this capability to KLEE,
and Dariz's patches have been since merged into mainline KLEE.%
\cite[overflow-merge]

This capability is reliant on Clang's support for Undefined Behavior Sanitizer
(also known as ``ubsan''), which in turn is based on Regehr et al's work on
integer overflow checking.\cite[ioc-paper] KLEE implements overflow checking
by performing arithmetic operations as-if done on wider types and then
checking upper half of the result. If it isn't empty, overflow must have
occured.

KLEE can check for overflow of both signed and unsigned integral types, but the
checks have to be turned on and/or off during tested program's compilation.
This is caused by KLEE's reliance on Clang's intrinsics.

\sec Real-Time safety-critical applications

\secc eMotor

eMotor is proprietary control software for Infineon Tricore TC1798 motor.

\secc MaCAN

MaCAN library\urlnote{https://github.com/CTU-IIG/macan} implements
MaCAN protocol for Linux, Infineon Tricore TC1798 and STM32 architectures.
MaCAN protocol builds upon CAN protocol to provide additional security
through authenticating control messages received from the network.%
\cite[MaCAN-paper]

The Macan library was designed to be crossplatform by only having single,
platform independent dependency, cryptographic library Nettle%prevent break
\urlnote{http://www.lysator.liu.se/~nisse/nettle/} and by separating platform
dependent code from bulk of the library.

\chap Toolchain and case study preparation

In this chapter I will talk about changes done to KLEE, eMotor and MaCAN
that I have done to allow using KLEE to test these two libraries. I will also
talk about other necessary preparations and problems I had to face along the
way, touching upon some ``personal'' experience gained during this thesis.

Virtually all my work is also available online, in a GitHub repository%
\urlnote{https://github.com/horenmar/thesis-setup-stable}.

\sec KLEE preparation

When I started working with the KLEE tool, it was reliant on LLVM-2.9 and
LLVM-GCC, which at the time was about 3 years outdated. Since then there was
significant work done to allow KLEE to work with newer version of the LLVM
toolchain and Clang instead of LLVM-GCC, but as of the time of writing, it 
officially supports only LLVM-2.9 coupled with LLVM-GCC.\cite[llvm-version]
It was also dependent on {\em extremely} outdated version of STP.
\rfc{Make a note about KLEE's posixy model}

This has lead to some initial trouble, because LLVM-2.9 does not compile
against newer versions of glibc and both STP and KLEE's POSIX modelling layer
have some problems because of their age as well. Together with desire to use
Clang's IntegerOverflowSanitizer, this lead me to use LLVM-3.4 toolchain and
while doing so enabled testing for integer overflows, it also led to trouble
with compiling programs spanning more than single source file. Since KLEE has
been relying on obsolete parts of LLVM's API to link together bitcode files
resulting from compilation of multiple source files and these were removed, it
was impossible to compile a multi-file application.

To solve this problem I used the WLLVM utility%
\urlnote{https://github.com/travitch/whole-program-llvm} created by Tristan
Ravitch. It works by using a compiler able to emit both normal object files
and LLVM bitcode, generating both and then saving bitcode into the normal
object file. During linking the bitcode sections are also linked together and
can then be extracted from the final binary, resulting in working, complete
bitcode file for KLEE.\cite[wllvm-working]

This worked, but only for generating binaries without integer overflow checking
enabled. Enabling integer overflow checking via command line arguments, as if
working with normal compiler has led to link time error,
\fnote{Approximately 200 lines long} which was solved by using a hack provided
on the KLEE mailing list.\cite[wllvm-patch] Afterwards I was able to compile
multi-file application into bitcode with integer overflow checking enabled.

\sec eMotor modifications

\rfc{Ehhh? I probably should note how its hard it was to modify properly, but
I don't know how much I can say about internal architecture and so on...}

\sec MaCAN modifications

As mentioned before, MaCAN's architecture has decoupled architecture specific
code from the general library code. This allowed me to make only minimal
changes to the general library part of MaCAN code, increasing validity of
performed tests, as only very small part of MaCAN behaviour is KLEE specific.

\rfc{specify changes}

\chap Evaluation

\sec Results - problems, bugs, solutions?

\rfc {Again, better headline} 

\sec Complexity, limitations, execution time

\sec KLEE fitness for purpose

\chap Conclusion



\bibchap
\usebib/c (simple) mybase
%\usebib/<sorttype> (<style>) <bibfile>
%sorttype c -- citation order in text
%sorttype s -- by key in style file


%Supposedly "Zadání práce" if in czech.
\app Specification

\picw=\hsize
\cinspic specification-en.pdf
\vfil\break
\picw=\hsize
\cinspic specification-cz.pdf

\nextoddpage


\app Glossary\par
\makeglos

\nextoddpage

\bye

