\input ctustyle
\input pdfuni
\input glosdata
\input opmac-bib

%\shortcitations %Would be normally defined by the template, but I decided
% to comment it out preventively.
\sortcitations  %Sort citation order for citation lists
%That means turn [5, 3, 4, 7] into [3, 4, 5, 7] or [3-5, 7]

\parskip=\medskipamount \parindent=0pt

\worktype [B/EN]
\faculty {F3}
\department {Department of Cybernetics}
\title {The Use of Symbolic Execution for Testing of Real-Time
        Safety-Related Software}
\titleCZ {Využití symbolické exekuce pro testování real-time,
          bezpečnostně kritického softwaru}
\author {Martin Hořeňovský}
\authorinfo {horenmar@fel.cvut.cz}
\supervisor {Ing. Michal Sojka, Ph.D.}
\studyinfo {Open Informatics --- Computer and Information Science}
\date {May 2015}
\abstractEN {Safety critical software is hard!.}
\keywordsEN {Symbolic execution, KLEE, automatic testing,
             security-critical systems, automotive domain}
\abstractCZ {Safety critical software is hard!
             \rfc{Translate the english abstract}}
\keywordsCZ {Symbolická exekuce, KLEE, automatické testování,
             bezpečnostně kritický software, automobilová doména
             \rfc{Standardní překlad??}}
\thanks{I would like to thank my supervisor Ing. Michal Sojka, Ph.D.
        for having patience with my lazy ass. \rfc{Selfcensorship?}
        I also want to thank Petr Olšák for creating almost unified template
        for CTU.}
\declaration {
I hereby declare that I made this on my own and I declared
all used sources according to ``Metodický pokyn o dodržování
etických principů při přípravě vysokoškolských závěřečných prací''

\vskip 4cm
\chyph
Prohlašuji, že jsem předloženou práci vypracoval samostatně
a že jsem uvedl veškeré použité informační zdroje v souladu
s Metodickým pokynem o dodržování etických principů při přípravě
vysokoškolských závěrečných prací.

\signature
}


%Some draft iteration related "defines"
\draft %-- Remove this to finalize pdf.
%\savetoner
 
\makefront




\chap Introduction

Words...

\rfc{Work these into the introduction somehow.}
While its original purpose was to test general purpose programs, we decided
to test its fitness for testing real-time safety critical software, because
such software's number of paths through code is relatively small.

Thus there is a need for secure safety-critical software.


\sec Motivation

\sec What is the goal

\sec Structure

\sec Following text



\chap Background and related technologies

Standard C places no constraints upon the result of program invoking undefined
behaviour (UB), and this is often interpreted by compilers as allowance to
generate arbitrary output for such program. It also defines many causes of
undefined behaviour, such as\fnote{Taken from ISO C99 Appendix J.2
\cite[iso-C99]}
\begitems
* Dereferencing uninitialized pointer
* Dereferencing a NULL pointer
* Dereferencing pointer to no longer valid object (ie freed object)
* Creating pointers outside of allocated memory
* Converting pointers to objects of incompatible types (ie converting "float*"
  to "int*")
* Signed integer overflow (unsigned overflow is well defined)
* Shifting values by more than its size (ie "int64_t i = 1 << 70")
* Evaluating arithmetic expression that would be mathematically undefined
  (ie division by zero)
\enditems
The willingness of compilers to exploit undefined behaviour (UB) in code has
already been documented as causing security bugs in real world
\cite[linux-kernel-vuln], but defined behaviour can lead to bugs as well.
A common example is unsigned overflow, which is well defined, but often is not
accounted for and breaks program's logic. 

While static analysis can find some of these potential defects (ie
dereferencing uninitialized pointers and incompatible pointer conversions),
it is not sound and gives both false positives and false negatives. Static
analysis is also unable to find integer overflows, as these are inherently
dynamic and the only viable way to detect them is runtime checking.

\rfc{Introduce possible bugs and give some background?}

\sec Safety-critical software and security

Safety-critical systems are those systems whose malfunction and/or failure
might result in death (or grievous injury) of people, severe damage to and/or
loss of equipment and environmental damage. These systems are increasingly
often implemented in software, as opposed to hardware, and new methods of
software defect prevention are needed.

There are various ways to decrease the number and frequency of software
malfunctions, such as specific development methodologies (ie MISRA C%
\urlnote{http://www.misra.org.uk/MISRAHome/WhatisMISRA/tabid/66/Default.aspx},
and JSF-AV C++ coding standards\urlnote{http://www.stroustrup.com/JSF-AV-rules.pdf})
which aim to provide safer subset of the language, thus decreasing possible
space for defects and set requirements for testing rigour. Similarly, since
compilation is another potential source of software defects, there are formally
provable compilers\urlnote{http://compcert.inria.fr/}.

In general, safety-critical systems are expected to be hard real-time and to be
fully defined for all possible inputs. This means that software contained
within must always respond under a fixed time-limit and have to fully define
its failure modes, even if the response is just turning off motor and engaging
emergency breaks.

Security used to be thought of as completely orthogonal to safety-critical
software, because such software was expected to be completely isolated from
outside world, and if networked, the network was thought to be completely
isolated from the outside world. These assumptions are becoming more and more
outdated, with recent example being the ability to locate and unlock Tesla
Model S electric car by hacking a trivially brute-forceable code.

\sec Symbolic execution

The term symbolic execution has been coined in year 1976 by James C. King in
article Symbolic execution and program testing
\cite[symbolic-execution-article]. Since then symbolic execution has been
implemented by various tools for various languages, from x86 assembly
\cite[s2e-paper], LLVM's IR (from C/C++) \cite[klee-paper, c9-paper] to higher
level languages such as the .NET framework \cite[pex-repair-paper].

The contents of rest of this section are heavily based on the KLEE paper
\cite[klee-paper] and the S2E paper \cite[s2e-paper].
Symbolic execution is a testing technique where program is run through an
interpreter, which allows for inputs to be symbolic, as opposed to concrete.
While run under interpreter, symbolic data (either input or variables) are
not actual data, but rather a set of boolean formulae that have been placed
upon them by conditions along the currently executing path. This allows the
interpreter to go through all possible paths in a program, without having to
generate all possible inputs. This is achieved by keeping track of all
conditions leading to any given path and using a SAT solver to A)~determine
whether any given path can be taken and  B)~generate a sample solution
(concretization of symbolic data) that will lead to any given path. As an
example, consider the following function:

\begtt
int is_odd(int n){
    if (n % 2) {
        return 1;
    } else {
        return 0;
    }
}
\endtt

It has $2^{32}$ possible concrete inputs, but as can be easily seen,
has only two paths through. Symbolic testing allows us to find both paths
without having to explore all $2^{32}$ inputs. If we mark the input as symbolic
and use KLEE to test this function, it outputs both paths and gives concretized
values that give full coverage.
\begtt
KLEE: done: total instructions = 29
KLEE: done: completed paths = 2
KLEE: done: generated tests = 2
...
args       : ['is_odd.o']
num objects: 1
object    0: name: 'n'
object    0: size: 4
object    0: data: 0
...
args       : ['is_odd.o']
num objects: 1
object    0: name: 'n'
object    0: size: 4
object    0: data: 1
\endtt

Unlike with fuzzing, time required for symbolic execution of any given program
doesn't increase exponentially with size of input, but rather increases with
amount of branches (possible paths) through the program. This allows use of
symbolic testing on much larger programs than just using random inputs. 

On the other hand, certain kinds of conditional branching are more or less
unsolvable. Consider checking cryptographic hash of a symbolic value against
predetermined result. For symbolic tool to be able to give us a concrete value
or a set of constraints is asking it to reverse a cryptographic hash, which is
generally regarded impossible without brute-force testing the input space, and
in special cases might be impossible completely. Other problematic constructs
are unbounded loops (IE those waiting for a hardware response) and infinite
loops, which prevent symbolic execution from terminating.

Various solutions to increase path coverage and exist, including parallelizing
independent paths \cite[c9-paper], usage of heuristics to guide search
\cite[klee-paper, symdrive-paper, c9-paper, kite-paper], usage of annotations
\cite[symdrive-paper] and selective symbolic execution \cite[s2e-paper].

\secc Existing tools

There exist various tools for symbolic execution, many of which are
based on KLEE \cite[symdrive-paper, c9-paper, s2e-paper, kite-paper].

Cloud9\urlnote{http://cloud9.epfl.ch/}
is a symbolic executor that can scale over clusters of machines, and
a cloud service for testing software \cite[c9-paper]. It's innovation is dynamic
partitioning of search space while having a shared-nothing architecture. It is
also capable of executing C++ code.

S2E\urlnote{http://s2e.epfl.ch/}
is a platform for analysing large scale programs In-Vivo. It accomplishes
this by using{\em selective symbolic execution} a technique that automatically
minimalizes amount of symbolically executed code within a binary. Together with
relaxed execution consistency, this allows S2E to analyse code as run in its
real environment \cite[s2e-paper].

SymDrive\urlnote{http://research.cs.wisc.edu/sonar/projects/symdrive/}
is a tool for testing Linux and FreeBSD drivers without hardware
\cite[symdrive-paper]. It uses static-analysis to automatically find driver
entry points and loops, which often allows it to test a driver without
requiring any modifications by its author and if it cannot create modified
driver automatically, it alerts the developer as to what changes are required 
\cite[symdrive-paper].%

Kite\urlnote{http://www.cs.ubc.ca/labs/isd/Projects/Kite/}
is a KLEE based tool that prunes its search space whenever a path is proven
to be infeasible. It is based on recent improvements of CDCL SAT solvers and
uses markedly different exploration strategy from other tools, in that it
looks for paths which allow it to ``learn'' the most, that is, prune the search
space the most \cite[kite-paper].

\sec KLEE

KLEE is a symbolic execution tool primarily geared towards performing
high-coverage tests on programs, originally created by Cadar et al
\cite[klee-paper]. 
It is built on the LLVM compiler infrastructure, using its Clang front-end to
convert C code to LLVM IR representation, which it then works on.

KLEE can find and show paths that lead to any case of
\begitems
* Assertion violation
* Access outside of allocated memory (including null pointer dereference and
  double free)
* Division by zero
* Integer overshift (shifting an integer by more than its size)
* Call to "abort()"
\enditems

Recently, KLEE was also extended to handle integer overflow checking, as
detailed in the next section.

\secc Principle of operation

\rfc{How does klee work, todo.}

\secc KLEE integer overflow checking

When I started working with KLEE, it was unable to detect integer overflow. We
decided to add support for checking integer overflow, but at the same time
Dariz Luca had implemented it as well and since his work has been mainlined
\cite[overflow-merge], I will talk about his implementation.

This capability relies on Clang's support for Undefined Behavior Sanitizer
(also known as ``ubsan''), which in turn is based on work by Regehr et al. on
integer overflow checking \cite[ioc-paper]. KLEE implements overflow checking
by performing arithmetic operations as-if done on double sized types and then
checking upper half of the result. If it is not empty, the operation must have
overflown.

KLEE can check for overflow of both signed and unsigned integral types, but the
checks have to be turned on and/or off during tested program's compilation.
This is caused by KLEE's reliance on Clang's intrinsics.

\sec Real-Time safety-critical applications

\secc eMotor

The eMotor driver is a proprietary control software module for AUTOSAR
developed by Infineon Technologies, consisting of MCAL and the eMotor control
module itself. It is interrupt driven design (the entire control algorithm is
executed inside the interrupt handler) and is designed to run on 32-bit Tricore
TC1798 microcontroller. It is supplied together with proprietary IDE, compiler,
assembler and linker.

\secc MaCAN

Because it was usually assumed that attackers do not have access to the
network inside vehicle, the standard communication protocol, CAN, was designed
for deterministic real-time communication, reliability and robustness and no
consideration was given to security. However modern vehicles often have at
least one remotely accessible interfaces and thus there is now a need to have
message security as part of the communication protocol.

The MaCAN protocol authenticates messages, giving a measure of message security
and has an advantage in that it builds upon the CAN bus and is backwards
compatible with already existing deployments of CAN.

MaCAN library\urlnote{https://github.com/CTU-IIG/macan} implements the
MaCAN protocol for Linux, Infineon Tricore TC1798 and STM32 architectures
\cite[MaCAN-paper]. It was designed to be cross-platform by only having
single, platform-independent dependency, cryptographic library Nettle%
\urlnote{http://www.lysator.liu.se/~nisse/nettle/} and by separating platform
dependent code from bulk of the library.

My investigation was done on a snapshot of the MaCAN library taken at commit
1dac9fed8b9777d32e0c28b2b826b8ac36f146a5
\urlnote{https://github.com/horenmar/macan/commit/1dac9fed8b9777d32e0c28b2b826b8ac36f146a5}
with added modification to allow testing with KLEE. I will talk about these
in the following chapter.




\chap Toolchain and case study preparation

In this chapter I will talk about changes done to KLEE, eMotor and MaCAN
that I have done to allow testing these two libraries using KLEE. I will also
talk about other necessary preparations and problems I had to face along the
way, touching upon some ``personal'' experience gained during this thesis.

Virtually all my work is also available online, in a GitHub repository%
\urlnote{https://github.com/horenmar/thesis-setup-stable}.

\sec KLEE preparation

When I started working with the KLEE tool, it was reliant on LLVM-2.9 and
LLVM-GCC, which at the time was about 3 years outdated. Since then there was
significant work done to allow KLEE to work with newer version of the LLVM
toolchain and Clang instead of LLVM-GCC, but as of the time of writing, it 
officially supports only LLVM-2.9 coupled with LLVM-GCC \cite[llvm-version].
It was also dependent on {\em extremely} outdated version of STP.

This has lead to some initial trouble, because LLVM-2.9 does not compile
against newer versions of glibc and both STP and KLEE's POSIX modelling layer
have some problems because of their age as well. Together with desire to use
Clang's IntegerOverflowSanitizer, this lead me to use LLVM-3.4 toolchain and
while doing so enabled testing for integer overflows, it also led to trouble
with compiling programs spanning more than single source file. Since KLEE has
been relying on obsolete parts of LLVM's API to link together bitcode files
resulting from compilation of multiple source files and these were removed, it
was impossible to compile a multi-file application.

To solve this problem I used the WLLVM utility%
\urlnote{https://github.com/travitch/whole-program-llvm} created by Tristan
Ravitch. It works by using a compiler able to emit both normal object files
and LLVM bitcode, generating both and then saving bitcode into the normal
object file. During linking the bitcode sections are also linked together and
can then be extracted from the final binary, resulting in working, complete
bitcode file for KLEE \cite[wllvm-working].

This worked, but only for generating binaries without integer overflow checking
enabled. Enabling integer overflow checking via command line arguments, as if
working with normal compiler has led to link time error
\fnote{Approximately 200 lines long}, which was solved by using a hack provided
on the KLEE mailing list \cite[wllvm-patch]. Afterwards I was able to compile
multi-file application into bitcode with integer overflow checking enabled.

\sec eMotor modifications

Because the eMotor's internal structure is rather weakly abstracted and
accesses to hardware registers are often interwoven inside functions, modifying
eMotor to support symbolic execution has proven to be prohibitively hard. This
has led to us giving up on testing eMotor.

\rfc{Write more about this?}

\sec MaCAN modifications

As mentioned before, MaCAN's architecture has decoupled architecture specific
code from the general library code. This allowed me to initially make no
changes to the library part of MaCAN code, shimming hardware dependencies to
return symbolic values when run under KLEE.

However, the MaCAN library inner working is deeply reliant on cryptography and
validating cryptography using symbolic execution is intractable. Because of
this I ended up having to bypass parts of the code, compromising completeness
of testing coverage to be able to analyse the rest of codebase.

More specifically, in addition to adding KLEE as a platform to the MaCAN project
and adding the necessary platform-specific scaffolding, I only had to perform
small modifications to the original library source in the form of conditional
compilation and create a dummy MaCAN node application, to create a valid
execution entry point for KLEE.

\rfc{Specify changes in more detail?}
All my modifications are publicly available as a fork of the original project
\urlnote{https://github.com/horenmar/macan/tree/klee}.

\chap Evaluation

In this chapter I will talk about results I obtained by running KLEE on the
MaCAN library to evaluate its viability as testing tool of real-time,
safety-critical software. Because of the already mentioned difficulties with
modifying eMotor to run under KLEE, all results in this chapter are from
running KLEE on the MaCAN library.

\sec Results - problems, bugs, solutions?

\rfc{Again, better headline.}
Running KLEE on the modified MaCAN library reports some potential errors, the
most common being potential unsigned integer overflows when working with system
time. However, because time is represented as 64 bit unsigned integer, these
were judged as mostly harmless. Not all potential time overflows were benign,
one invoked undefined behaviour and another has caused a bug that has also been
found independently.

Summary of overflows found can be seen in table~\ref[overflow-results].
%%%%%%
% Results table
%%%%%%
\midinsert \clabel[overflow-results]{Number of overflows found}
\ctable{lr}{
\hfil type of overflow & number \crl \tskip4pt
    benign & 5 \cr
    causing bugs & 1 \cr
    causing UB & 1 \cr
}
\caption/t Number of overflows found.
\endinsert
\rfc{Complete these results as they are improved.}

The one case of undefined behaviour causing overflow was in function checking
authenticity of received message. The programmer wanted to test whether the
message was authentic, assuming it was sent either slightly before ``now''
(that is, current MaCAN time), now, or after now and wrote this:
\begtt
uint64_t time;
int i;
...
time = macan_get_time(ctx);

for (i = -1; i <= 1; i++) {
    *ftime = htole32((int)time + i);
    macan_aes_cmac(skey, len, cmac, plain);

    if (memcmp(cmac4, cmac, 4) == 0) {
        return 1;
    }
}
\endtt
where the expression "(int)time + i" in line 
\begtt
*ftime = htole32((int)time + i);
\endtt
performed signed arithmetic that can easily overflow. After finding this bug,
it was fixed in mainline MaCAN, changing the problematic part of the code to
the following:
\begtt
int delta_t;
uint32_t time = (uint32_t)macan_get_time(ctx);
for (delta_t = -1; delta_t <= 1; delta_t++) {
    *ftime = htole32(time + (uint32_t)delta_t);
}
\endtt
While this new version can still overflow (in fact, it has to overflow to work
properly), this new overflow is well defined from the language point of view
and is benign as far as function is intended.

Another non-benign overflow was found in function that receives time from the
MaCAN network and attempts to adjust local time to keep it in sync. It attempts
to calculate time in microseconds and place the result into a 64 bit sized
variable, which would be large enough, but the multiplication itself is
performed with 32 bits of precision and the results will overflow after approx.
68 minutes.
\begtt
uint32_t time_ts;
uint64_t time_ts_us;
...
time_ts_us = time_ts * ctx->config->time_div;
\endtt
This bug was also found independently by Michal Sojka when he was presenting
MaCAN's at a conference and this was the implemented fix:
\begtt
uint32_t time_ts;
uint64_t time_ts_us;
...
time_ts_us = (uint64_t)time_ts * ctx->config->time_div;
\endtt
Changing "time_ts"'s type to 64 bit unsigned integer caused the multiplication
to be performed with 64 bits of precision, changing the overflow from
bug-causing to benign (64 bit integer has enough precision to represent more
than 500000 years in microseconds).

Some potential overflows KLEE found were classified as benign. This either
meant that they only occurred within 64 bit arithmetic and thus could happen
only theoretically, or they were intended. In fact, just the event loop
implementation contains three benign potential overflows. Two examples of such
overflows follow.
\begtt
w->expire_us = read_time() + w->repeat_us;
\endtt
\begtt
(read_time() + (uint64_t)ctx->time.offs) / ctx->config->time_div;
\endtt
For either of there to overflow, the total run-time of given MaCAN network
would have to exceed the aforementioned 500000 years that are representable
within 64 bit unsigned variable and as such, are harmless.

\sec Complexity, limitations, execution time

KLEE's complexity is exponential in both memory (because the number of possible
path generally increases exponentially with encountered conditional branches)
and in CPU time (because it attempts to solve SAT at every branch). The memory
complexity can be mitigated at the cost of further increasing runtime, by
running KLEE with search strategy set to either DFS or IDDFS (which is only
experimentally supported), but there is no way to reduce the CPU time
complexity.

\rfc{Update time and test cases after finishing}
\rfc{Insert ``If the task has not been killed, it is still runnin'' joke
somewhere.}
This has shown itself while we were using KLEE to test the MaCAN library, when
after 2 days, KLEE still has not finished executing the test program. It is
also somewhat mitigated by the fact that KLEE does not have to finish running
completely to find bugs and/or to start outputting possible paths through the
program. If I have not modified the MaCAN library to bypass cryptography, the
execution would be completely intractable.

\sec KLEE fitness for purpose




\chap Conclusion



\bibchap
\usebib/c (simple) mybase
%\usebib/<sorttype> (<style>) <bibfile>
%sorttype c -- citation order in text
%sorttype s -- by key in style file


%Supposedly "Zadání práce" if in czech.
\app Specification

\picw=\hsize
\cinspic specification-en.pdf
\vfil\break
\picw=\hsize
\cinspic specification-cz.pdf
\nextoddpage


\app Glossary\par
\makeglos

\nextoddpage

\bye

